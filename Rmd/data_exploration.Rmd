---
title: "data_exploration"
author: "Tianyu Luo; Nanxin Li; Xuanbo Han"
output: pdf_document
geometry: margin=0.5in
urlcolor: blue
---
# Contribution:

# Introduction:

# Data Description: 

```{r}
# Library imports
library(dplyr)
library(ggplot2)

# load the dataset
data <- read.csv("../data/most-streamed-spotify-songs-2024.csv")
```

```{r}
# Check data types
sapply(data, class)
```
response = Spotify Stream
predictor = Spotify Playlist Count, Youtube Views, Youtube Likes, TikTok Posts, TikTok Views, Apple Music Playlist Count, Shazam Counts, AirPlay Spins, Explicit Track(0 = Clean, 1 = Explicit Content)

```{r}
# Remove spaces and special characters from column names (in case there is any)
names(data) <- gsub(" ", ".", names(data))
names(data) <- gsub("-", ".", names(data))

names(data)
```
```{r}
# Take the features we need to use from the data table
features <- c("Spotify.Streams", "Spotify.Playlist.Count", "YouTube.Views", 
              "YouTube.Likes", "TikTok.Posts", "TikTok.Views", 
              "Apple.Music.Playlist.Count", "Shazam.Counts", "AirPlay.Spins")

# From the above type check for each variable, every column is in character
# and numbers are in format xxx,xxx,xxx so commas in between must be removed
convert_to_numeric <- function(x) {
  # If already numeric, return the original value since no changes are needed
  if(is.numeric(x)) return(x)
  
  x <- gsub(",", "", x)           # Remove commas
  x <- gsub(" ", "", x)           # Remove spaces
  x <- trimws(x)                  # Remove leading/trailing whitespace
  
  # Convert to numeric
  x <- as.numeric(x)
  
  return(x)
}

for(col in features) {
  data[[col]] <- convert_to_numeric(data[[col]])
}
cat("Number of rows remaining:", nrow(data), "\n")
```

```{r}
# Check which rows have complete data for key variables
complete_rows <- complete.cases(data[, features])
# Keep only the rows with non-missing values for all features
spotify_clean <- data[complete_rows, ]

cat("Number of rows remaining:", nrow(spotify_clean), "\n")
```


Since after cleaning the dataset, we are remained with 2916 valid entries, we can still assume that we can train a valid model from this dataset. 

```{r}
# Remove Duplicate data from dataset (prevent the same song being used twice in the model)
# Check for duplicate ISRCs since the same ISRC represent the same song
if("ISRC" %in% names(data)) {
  duplicate_isrc <- sum(duplicated(data$ISRC))
  cat("Songs with duplicate ISRC:", duplicate_isrc, "\n")
  
  # Remove duplicates by ISRC, keeping first occurrence
  spotify_clean <- spotify_clean[!duplicated(spotify_clean$ISRC), ]
}
```

```{r}
preliminary_model <- lm(Spotify.Streams ~ Spotify.Playlist.Count + YouTube.Views + YouTube.Likes + TikTok.Posts + TikTok.Views + Apple.Music.Playlist.Count + Shazam.Counts + AirPlay.Spins + Explicit.Track, data=spotify_clean)

summary(preliminary_model)
```

```{r, echo=F, fig.width=8, fig.height=11}
e_hat <- resid(preliminary_model)
y_hat <- fitted(preliminary_model)

feature_indices <- match(features, names(spotify_clean))

par(mfrow=c(4,3))
plot(spotify_clean$Spotify.Streams ~ y_hat, ylab="Spotify Streams", xlab="Fitted")
plot(e_hat ~ y_hat, ylab="Residuals", xlab="Fitted")
for(i in feature_indices){
 plot(e_hat ~ spotify_clean[,i], ylab="Residuals", xlab=names(spotify_clean)[i])
}
plot(e_hat, ylab="Residuals", xlab="Observation number")
qqnorm(e_hat)
qqline(e_hat)
```


# Ethics Discussion

# Preliminary Results

# Plan

# Bibliography
