---
title: "data_exploration"
author: "Tianyu Luo; Nanxin Li; Xuanbo Han"
output: pdf_document
geometry: margin=0.5in
urlcolor: blue
---

```{r, warning=FALSE, message=FALSE}
# If library imports failed, uncomment to install packages
# install.packages("car")
# install.packages("zoo")

# Library imports
library(tidyverse)
library(car)
library(zoo)

# load the dataset
# If you are using vs code, please remove the ../ from the path.
data <- read.csv("../data/most-streamed-spotify-songs-2024.csv") 
```

## Data Cleaning

```{r}
# Check data types
sapply(data, class)
```

response = Spotify Stream predictor = Spotify Playlist Count, Youtube Views, Youtube Likes, TikTok Posts, TikTok Views, Apple Music Playlist Count, Shazam Counts, AirPlay Spins, Explicit Track(0 = Clean, 1 = Explicit Content)

```{r}
# Remove spaces and special characters from column names (in case there is any)
names(data) <- gsub(" ", ".", names(data))
names(data) <- gsub("-", ".", names(data))

names(data)
```
# Preliminary Model
```{r}
# Take the features we need to use from the data table
features <- c("Spotify.Streams", "Spotify.Playlist.Count", "YouTube.Views", 
              "YouTube.Likes", "TikTok.Posts", "TikTok.Views", 
              "Apple.Music.Playlist.Count", "Shazam.Counts", "AirPlay.Spins")
```

```{r}
# From the above type check for each variable, every column is in character
# and numbers are in format xxx,xxx,xxx so commas in between must be removed
convert_to_numeric <- function(x) {
  # If already numeric, return the original value since no changes are needed
  if(is.numeric(x)) return(x)
  
  x <- gsub(",", "", x)           # Remove commas
  x <- gsub(" ", "", x)           # Remove spaces
  x <- trimws(x)                  # Remove leading/trailing whitespace
  
  # Convert to numeric
  x <- as.numeric(x)
  
  return(x)
}

for(col in features) {
  data[[col]] <- convert_to_numeric(data[[col]])
}
cat("Number of rows remaining:", nrow(data), "\n")
```

```{r}
# Check which rows have complete data for key variables
complete_rows <- complete.cases(data[, features])
# Keep only the rows with non-missing values for all features
spotify_clean <- data[complete_rows, ]

cat("Number of rows remaining:", nrow(spotify_clean), "\n")
```

Since after cleaning the dataset, we are remained with 2916 valid entries, we can still assume that we can train a valid model from this dataset.

```{r}
# Remove Duplicate data from dataset (prevent the same song being used twice in the model)
# Check for duplicate ISRCs since the same ISRC represent the same song
if("ISRC" %in% names(data)) {
  duplicate_isrc <- sum(duplicated(data$ISRC))
  cat("Songs with duplicate ISRC:", duplicate_isrc, "\n")
  
  # Remove duplicates by ISRC, keeping first occurrence
  spotify_clean <- spotify_clean[!duplicated(spotify_clean$ISRC), ]
}

predictors <- c("Spotify.Playlist.Count", "YouTube.Views", "YouTube.Likes", 
                "TikTok.Posts", "TikTok.Views", "Apple.Music.Playlist.Count", 
                "Shazam.Counts", "AirPlay.Spins")
```

```{r}
# For exporting the cleaned dataset
variables_to_keep <- c(features, "Explicit.Track")

# Create cleaned dataset with only needed variables
spotify_model_data <- spotify_clean[, variables_to_keep]

# Export to CSV
write.csv(spotify_model_data, "../data/spotify_cleaned.csv", row.names = FALSE)
```


## Exploratory Data Analysis

```{r}
# Create response + predictor summary table (not including explicit track - it will presented in a separate frequency table)
summary_table <- data.frame(
  Variable = character(),
  Min = numeric(),
  Q1 = numeric(),
  Median = numeric(),
  Mean = numeric(),
  Q3 = numeric(),
  Max = numeric(),
  stringsAsFactors = FALSE
)

for (f in features) {
  x <- spotify_clean[[f]]
  
  summary_table <- rbind(summary_table, data.frame(
    Feature = f,
    Min = min(x, na.rm = TRUE),
    Q1 = quantile(x, 0.25, na.rm = TRUE),
    Median = median(x, na.rm = TRUE),
    Mean = mean(x, na.rm = TRUE),
    Q3 = quantile(x, 0.75, na.rm = TRUE),
    Max = max(x, na.rm = TRUE)
  ))
}

# remove rownames to avoid quantile range being printed accidentally
rownames(summary_table) <- NULL

# Print table
print(summary_table)
```

```{r}
# reshape dataset to long format and add predictor layers for scatterplots
spotify_long <- spotify_clean %>%
  select(Spotify.Streams, all_of(predictors)) %>%
  pivot_longer(cols = all_of(predictors),
               names_to = "Predictor",
               values_to = "Value")
```

```{r}
# Create plot
ggplot(spotify_long, aes(x = Value, y = Spotify.Streams)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  facet_wrap(~ Predictor, scales = "free")
```

```{r}
# Create histograms
ggplot(spotify_long, aes(x = Value)) +
  geom_histogram(fill = "lightblue", color = "black", bins = 30) +
  facet_wrap(~ Predictor, scales = "free", ncol = 2) +
  labs(title = "Distribution of Each Predictor",
       y = "Frequency")

table(spotify_clean$Explicit.Track)
```

## Model Fitting

```{r}
preliminary_model <- lm(Spotify.Streams ~ Spotify.Playlist.Count + YouTube.Views + YouTube.Likes + TikTok.Posts + TikTok.Views + Apple.Music.Playlist.Count + Shazam.Counts + AirPlay.Spins + Explicit.Track + Spotify.Playlist.Count:Explicit.Track, data=spotify_clean)

summary(preliminary_model)
```

## Problematic Observations in Preliminary Model
```{r}
n <- nrow(spotify_clean)
p <- length(coef(preliminary_model))-1
hcut <- 2*(p + 1)/n
cookcut <- qf(0.5, df1=p+1, df2=n-p-1)
fitcut <- 2 * sqrt((p + 1) / n)
betacut <- 2 / sqrt(n)
```

```{r}
h_ii <- hatvalues(preliminary_model)
r_i <- rstandard(preliminary_model)
D_i <- cooks.distance(preliminary_model)
dffits_i <- dffits(preliminary_model)
dfbetas_i <- dfbetas(preliminary_model)
```


```{r}
# indices flagged by each rule
lev_idx      <- which(h_ii > hcut)                       # leverage points
reg_out_idx  <- which(r_i > 4 | r_i < -4)                # regression outliers
cook_idx     <- which(D_i > cookcut)                     # Cook's distance
dffits_idx   <- which(abs(dffits_i) > fitcut)            # DFFITS
dfbetas_idx  <- which(apply(abs(dfbetas_i) > betacut, 1, any))  # any beta
```

```{r}
all_influential_idx <- sort(unique(c(
  lev_idx,
  reg_out_idx,
  cook_idx,
  dffits_idx,
  dfbetas_idx
)))
```

```{r}
# proportion of influential points in spotify_valid
prop_influential <- length(all_influential_idx) / n

prop_influential
```

## Multicollinearity

```{r}
vif(preliminary_model)
```
The preliminary fitted model is $$Spotify.Playlist.Count = -22100000 + 4325\text{Spotify.Playlist Count} + 0.02179\text{YouTube.Views} + 11.7\text{YouTube.Likes} + 31.6\text{TikTok.Posts} + 0.02417\text{TikTok.Views} + 1682000\text{Apple.Music.Playlist.Count} + 8.444\text{Shazam.Counts} - 0.03575\text{AirPlay.Spins} + 7944000\text{Explicit.Track} - -90.08\text{Spotify.Playlist.Count}*{Explicit.Track}$$ Firstly, we check the conditional mean response condition to make sure that the observations from residual plots are conclusive. From each response vs. predictor plot, there is no obvious non-linear relationship from the plot, so the conditional mean response condition holds. Also, from scatter plot between each pair of predictor, no pair of predictors seem to exhibit a significant non-linear pattern, so the conditional mean predictor condition also holds.

Secondly, from the residual vs. fitted plot, a clear fanning pattern is present indicating a non-constant variance in the residuals. Also, the qqnorm plot demonstrates a non-linear pattern and largely deviates at the head and tail of the distribution. This indicates a violation in the normality assumption. In the observation of residual vs. fitted and each pair of residual vs. predictor, there is no obvious non-linear pattern or clustering presented, after examining the nature of each feature, there is likely no violation in the linearity and uncorrelated error assumption.

# Final Model
## Feature Engineering

```{r}
# Ensure correct format
spotify_clean$Release.Date <- as.Date(spotify_clean$Release.Date, format = "%d/%m/%Y")

# Check conversion
head(spotify_clean$Release.Date)

# Set baseline as the earliest release date
baseline_date <- min(spotify_clean$Release.Date, na.rm = TRUE)
baseline_date  # Optional: print baseline

# Compute time difference in months
spotify_clean$time <- as.numeric(
  (as.yearmon(spotify_clean$Release.Date) - as.yearmon(baseline_date)) * 12
)

# Convert to integer (if preferred)
spotify_clean$time <- round(spotify_clean$time)

# Check results
head(spotify_clean[, c("Release.Date", "time")])
```

Clean Dataset
```{r}
# Remove observations with missing timestamp (either Release.Date or time is NA)
spotify_time <- spotify_clean[!is.na(spotify_clean$Release.Date) & !is.na(spotify_clean$time), ]

# Check number of remaining observations
nrow(spotify_time)

# Optional: view first few cleaned rows
head(spotify_time[, c("Release.Date", "time")])
```

```{r}
time_model <- lm(Spotify.Streams ~ time + Spotify.Playlist.Count + YouTube.Views + YouTube.Likes + TikTok.Posts + TikTok.Views + Apple.Music.Playlist.Count + Shazam.Counts + AirPlay.Spins + Explicit.Track + Spotify.Playlist.Count:Explicit.Track, data=spotify_time)
summary(time_model)
```

```{r}
vif(time_model)
```

```{r}
reduced_time_model <- lm(Spotify.Streams ~ time + YouTube.Views + YouTube.Likes + TikTok.Posts + TikTok.Views + Apple.Music.Playlist.Count + Shazam.Counts + AirPlay.Spins + Explicit.Track + Spotify.Playlist.Count:Explicit.Track, data=spotify_time)
summary(reduced_time_model)
```

```{r}
reduced_time_model2 <- lm(Spotify.Streams ~ time + YouTube.Views + YouTube.Likes + TikTok.Posts + Apple.Music.Playlist.Count + Shazam.Counts + AirPlay.Spins + Explicit.Track + Spotify.Playlist.Count:Explicit.Track, data=spotify_time)
summary(reduced_time_model2)
```

```{r}
vif(reduced_time_model2)
```

```{r}
reduced_time_model3 <- lm(Spotify.Streams ~ time + YouTube.Views + YouTube.Likes + TikTok.Posts + Apple.Music.Playlist.Count + Shazam.Counts + Explicit.Track + Spotify.Playlist.Count:Explicit.Track, data=spotify_time)
summary(reduced_time_model3)
```

```{r, echo=F, fig.width=8, fig.height=11}
e_hat <- resid(reduced_time_model3)
y_hat <- fitted(reduced_time_model3)

feature_indices <- match(features, names(spotify_time))

par(mfrow=c(4,3))
plot(spotify_time$Spotify.Streams ~ y_hat, ylab="Spotify Streams", xlab="Fitted")
plot(e_hat ~ y_hat, ylab="Residuals", xlab="Fitted")
for(i in feature_indices){
 plot(e_hat ~ spotify_time[,i], ylab="Residuals", xlab=names(spotify_time)[i])
}
plot(e_hat, ylab="Residuals", xlab="Observation number")
qqnorm(e_hat)
qqline(e_hat)
```

The above model has decently large $R^2$ and adjusted $R^2$, but there are clearly assumption violations

```{r}
# boxCox transformation applied to response variable
bc <- boxCox(reduced_time_model3)

yLambda <- bc$x[which.max(bc$y)]

# Apply power transformation to predictor variables
tfs <- powerTransform(cbind(spotify_time[,feature_indices]))
summary(tfs)
```

```{r}
# Add transformed column
spotify_time$tf_streams <- (spotify_time$Spotify.Streams)**(2/5)
```


```{r}
tf_reduced_time_model1 <- lm(tf_streams ~ time + Spotify.Playlist.Count + YouTube.Likes + TikTok.Posts + Apple.Music.Playlist.Count, data=spotify_time)
summary(tf_reduced_time_model1)
```

```{r}
tf_features <- c("tf_streams", "time", "Spotify.Playlist.Count",
              "YouTube.Likes", "TikTok.Posts", 
              "Apple.Music.Playlist.Count")
```


```{r, echo=F, fig.width=8, fig.height=11}
e_hat <- resid(tf_reduced_time_model1)
y_hat <- fitted(tf_reduced_time_model1)

feature_indices <- match(tf_features, names(spotify_time))

par(mfrow=c(4,3))
plot(e_hat ~ y_hat, ylab="Residuals", xlab="Fitted")
for(i in feature_indices){
 plot(e_hat ~ spotify_time[,i], ylab="Residuals", xlab=names(spotify_time)[i])
}
plot(e_hat, ylab="Residuals", xlab="Observation number")
qqnorm(e_hat)
qqline(e_hat)
```

Normality violation is mitigated but non-linearity and non-constant variance are still present

```{r}
# boxCox transformation applied to response variable
bc <- boxCox(tf_reduced_time_model1)

X <- spotify_time[, feature_indices]

# Shift features if needed
for (j in seq_along(X)) {
  min_val <- min(X[, j], na.rm = TRUE)
  if (min_val <= 0) {
    X[, j] <- X[, j] + abs(min_val) + 1  # Shift to make strictly positive
  }
}

# Apply power transformation
tfs <- powerTransform(X)
summary(tfs)
```

```{r}
# Add sqrt-transformed column
spotify_time$tf_time <- (spotify_time$time) ** 5

# Optional: view first few rows to verify
head(spotify_time[, c("time", "tf_time")])
```

```{r}
tf_reduced_time_model2 <- lm(tf_streams ~ tf_time + Spotify.Playlist.Count + YouTube.Likes + TikTok.Posts + Apple.Music.Playlist.Count, data=spotify_time)
summary(tf_reduced_time_model2)
```

```{r}
tf_features <- c("tf_streams", "tf_time", "Spotify.Playlist.Count",
              "YouTube.Likes", "TikTok.Posts", 
              "Apple.Music.Playlist.Count")
```


```{r, echo=F, fig.width=8, fig.height=11}
e_hat <- resid(tf_reduced_time_model2)
y_hat <- fitted(tf_reduced_time_model2)

feature_indices <- match(tf_features, names(spotify_time))

par(mfrow=c(4,3))
plot(e_hat ~ y_hat, ylab="Residuals", xlab="Fitted")
for(i in feature_indices){
 plot(e_hat ~ spotify_time[,i], ylab="Residuals", xlab=names(spotify_time)[i])
}
plot(e_hat, ylab="Residuals", xlab="Observation number")
qqnorm(e_hat)
qqline(e_hat)
```

non-constant variance are slightly mitigated, but non-linearity are still present. Apply more transformations

```{r}
# Add transformed column
spotify_time$tf_youtube <- (spotify_time$YouTube.Likes)**(0.3)
spotify_time$tf_tiktok <- (spotify_time$TikTok.Posts)**(0.2)
spotify_time$tf_apple <- (spotify_time$Apple.Music.Playlist.Count)**(0.2)
```

```{r}
tf_reduced_time_model3 <- lm(tf_streams ~ tf_time + Spotify.Playlist.Count + tf_youtube + tf_tiktok + Apple.Music.Playlist.Count + tf_time:Spotify.Playlist.Count, data=spotify_time)
summary(tf_reduced_time_model3)
```

```{r}
tf_features <- c("tf_streams", "tf_time", "Spotify.Playlist.Count",
              "tf_youtube", "tf_tiktok", 
              "tf_apple")
```


```{r, echo=F, fig.width=8, fig.height=11}
e_hat <- resid(tf_reduced_time_model3)
y_hat <- fitted(tf_reduced_time_model3)

feature_indices <- match(tf_features, names(spotify_time))

par(mfrow=c(4,3))
plot(e_hat ~ y_hat, ylab="Residuals", xlab="Fitted")
for(i in feature_indices){
 plot(e_hat ~ spotify_time[,i], ylab="Residuals", xlab=names(spotify_time)[i])
}
plot(e_hat, ylab="Residuals", xlab="Observation number")
qqnorm(e_hat)
qqline(e_hat)
```

```{r}
n <- nrow(spotify_time)
p <- length(coef(tf_reduced_time_model3))-1
hcut <- 2*(p + 1)/n
cookcut <- qf(0.5, df1=p+1, df2=n-p-1)
fitcut <- 2 * sqrt((p + 1) / n)
betacut <- 2 / sqrt(n)
```

```{r}
h_ii <- hatvalues(tf_reduced_time_model3)
r_i <- rstandard(tf_reduced_time_model3)
D_i <- cooks.distance(tf_reduced_time_model3)
dffits_i <- dffits(tf_reduced_time_model3)
dfbetas_i <- dfbetas(tf_reduced_time_model3)
```


```{r}
# indices flagged by each rule
lev_idx      <- which(h_ii > hcut)                       # leverage points
reg_out_idx  <- which(r_i > 4 | r_i < -4)                # regression outliers
cook_idx     <- which(D_i > cookcut)                     # Cook's distance
dffits_idx   <- which(abs(dffits_i) > fitcut)            # DFFITS
dfbetas_idx  <- which(apply(abs(dfbetas_i) > betacut, 1, any))  # any beta
```

```{r}
all_influential_idx <- sort(unique(c(
  lev_idx,
  reg_out_idx,
  cook_idx,
  dffits_idx,
  dfbetas_idx
)))
```

```{r}
# proportion of influential points
prop_influential <- length(all_influential_idx) / n

prop_influential
```

```{r}
# index of most influential point among all observations
most_inf_idx <- which.max(D_i)

most_inf_idx
```

After verifying this entry is incorrectly labelled, so is thus removed

```{r}
spotify_time <- spotify_time[-most_inf_idx, ]
```

```{r}
tf_reduced_time_model4 <- lm(tf_streams ~ tf_time + Spotify.Playlist.Count + tf_youtube + tf_tiktok + Apple.Music.Playlist.Count + tf_time:Spotify.Playlist.Count, data=spotify_time)
summary(tf_reduced_time_model3)
```

```{r}
tf_features <- c("tf_streams", "tf_time", "Spotify.Playlist.Count",
              "tf_youtube", "tf_tiktok", 
              "tf_apple")
```


```{r, echo=F, fig.width=8, fig.height=11}
e_hat <- resid(tf_reduced_time_model4)
y_hat <- fitted(tf_reduced_time_model4)

feature_indices <- match(tf_features, names(spotify_time))

par(mfrow=c(4,3))
plot(e_hat ~ y_hat, ylab="Residuals", xlab="Fitted")
for(i in feature_indices){
 plot(e_hat ~ spotify_time[,i], ylab="Residuals", xlab=names(spotify_time)[i])
}
plot(e_hat, ylab="Residuals", xlab="Observation number")
qqnorm(e_hat)
qqline(e_hat)
```

```{r}
# Load broom for tidy extraction (part of tidyverse)
library(broom)

# 1. Helper function to calculate Standardized Coefficients
get_std_coefs <- function(model, model_name) {
  # Extract coefficients
  tidy_df <- tidy(model) %>% filter(term != "(Intercept)")
  
  # Get Standard Deviations of Y (Response) and X (Predictors)
  sd_y <- sd(model$model[[1]])
  # Use model.matrix to correctly handle interaction terms and transforms
  sd_x <- apply(model.matrix(model)[, -1], 2, sd) 
  
  # Calculate Standardized Estimate: Beta * (SD_x / SD_y)
  tidy_df$std_estimate <- tidy_df$estimate * (sd_x[tidy_df$term] / sd_y)
  
  # Add Model Label
  tidy_df$model_label <- model_name
  return(tidy_df)
}

# 2. Combine Data from both models
# Note: Using 'tf_reduced_time_model4' as your final model
plot_data <- rbind(
  get_std_coefs(preliminary_model, "Preliminary (Raw)"),
  get_std_coefs(tf_reduced_time_model4, "Final (Transformed)")
)

# 3. Create the Forest Plot
ggplot(plot_data, aes(x = std_estimate, y = reorder(term, abs(std_estimate)), color = model_label)) +
  geom_point(size = 3) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray50") +
  labs(
    title = "Comparison of Standardized Coefficients",
    subtitle = "Relative importance of predictors (scaled by Standard Deviation)",
    x = "Standardized Effect Size (Beta)",
    y = "Predictor",
    color = "Model"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```


TODO: ANOVA to justify model parameters changes and discuss problematic Observations
